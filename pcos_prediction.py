# -*- coding: utf-8 -*-
"""PCOS PREDICTION.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1N7dPNi6A_8QuHX9RYEcfN0mtogjWLRNV

Importing Libraries and Reading the Dataset
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px

pcos = pd.read_excel('pcos.xlsx')

pcos.head()

pcos.info()

pcos.describe()

"""Data Cleaning"""

pcos.drop(columns=['Sl. No', 'Patient File No.', 'Unnamed: 44'], inplace = True)

pcos.isnull().sum()

pcos['Marraige Status (Yrs)'].fillna(pcos['Marraige Status (Yrs)'].mode()[0], inplace = True)

pcos['Fast food (Y/N)'].fillna(pcos['Fast food (Y/N)'].mode()[0], inplace = True)

pcos.isnull().sum()

pcos.rename(columns={'Marraige Status (Yrs)':'YearsMarried', 'No. of aborptions':'No of abortions', 'Follicle No. (L)':'Follicle_No_L', 'Follicle No. (R)':'Follicle_No_R', 'Weight (Kg)':'Weight_kg', 'Cycle length(days)':'Cycle_length', 'Weight gain(Y/N)':'Weight_gain', 'hair growth(Y/N)':'hair_growth', 'hair growth(Y/N)':'hair_growth', 'Skin darkening (Y/N)':'skin_darkening', 'Hair loss(Y/N)':'Hair_loss', 'Fast food (Y/N)':'Fast_food', 'Cycle(R/I)':'cycle', 'Pimples(Y/N)':'Pimples', 'AMH(ng/mL)':'amh_ng_ml', 'Age(yrs)':'age_yrs', 'Waist(inch)':'Waist_inch'}, inplace = True)

pcos.info()

pcos["amh_ng_ml"] = pd.to_numeric(pcos["amh_ng_ml"], errors="coerce")

pcos["II    beta-HCG(mIU/mL)"] = pd.to_numeric(pcos["II    beta-HCG(mIU/mL)"], errors="coerce")

pcos.head()

pcos.info()

pcos['amh_ng_ml'].fillna(pcos['amh_ng_ml'].mode()[0], inplace = True)

pcos['II    beta-HCG(mIU/mL)'].fillna(pcos['II    beta-HCG(mIU/mL)'].mode()[0], inplace = True)

pcos.info()

"""Exploratory Analysis"""

pcos.head()

colors = ['green', 'red' ]
sns.countplot(x='PCOS (Y/N)',data=pcos, palette=colors)
plt.xlabel('PCOS')
plt.ylabel('Count')
plt.title('Count of PCOS')
plt.show()

plt.figure(figsize = (25,25))
sns.heatmap(pcos.corr(), annot=True)

matrix=np.triu(pcos.corr())
plt.figure(figsize=(25, 25))
sns.heatmap(pcos.corr(),fmt=".2f",annot=True, mask=matrix, cmap='coolwarm')

sns.scatterplot(x = 'BMI', y= 'Weight_gain', data=pcos, hue = 'PCOS (Y/N)')

sns.scatterplot(x = 'cycle', y= 'Follicle_No_L', data=pcos, hue = 'PCOS (Y/N)')

sns.pairplot(pcos.loc[:,['cycle','Weight_gain', 'hair_growth','skin_darkening', 'Hair_loss', 'Pimples', 'Fast_food', 'PCOS (Y/N)']], hue = 'PCOS (Y/N)', kind = 'reg')

#Create a boxplot for each numeric column
for col in pcos.select_dtypes(include=["int", "float"]):
    sns.boxplot(x='PCOS (Y/N)', y=pcos[col], data=pcos)
    plt.show()

# Calculate the z-score for each numeric column
for col in pcos.select_dtypes(include=["int", "float"]):
    z_scores = (pcos[col] - pcos[col].mean()) / pcos[col].std()

# Identify outliers based on a threshold (e.g., z-score > 3)
outliers = pcos[abs(z_scores) > 3]

# Print the number of outliers for each column
print(f"Number of outliers in {col}: {outliers.shape[0]}")

sns.scatterplot(x = 'cycle', y= 'Endometrium (mm)', data=pcos, hue = 'PCOS (Y/N)')

# plt.bar('Endometrium (mm)', 'PCOS (Y/N)', color = 'r')
# plt.bar('Endometrium (mm)', 'Cycle(R/I)', bottom = 'PCOS (Y/N)', color = 'b')
# plt.show()

"""Insights"""

correlation_sort = pcos.corr()['PCOS (Y/N)'].abs().sort_values(ascending=False)
correlation_sort

important_features = correlation_sort[0:16]
important_features

pcos_new = pcos[['PCOS (Y/N)','Follicle_No_R','Follicle_No_L','skin_darkening','hair_growth','Weight_gain','cycle','Fast_food','Pimples','amh_ng_ml','Weight_kg','BMI','Cycle_length','Hair_loss','age_yrs','Waist_inch']]

pcos_new.head(10)

plt.figure(figsize=(11,11))
sns.heatmap(pcos_new.corr(),annot=True)
plt.show()

#checking if the label column is balanced
pcos_new['PCOS (Y/N)'].value_counts()

#lets balance the column using oversampler
#split the dataset into x and y

X = pcos_new.drop('PCOS (Y/N)', axis=1)
y = pcos_new['PCOS (Y/N)']

X.shape

y.shape

#import oversampler from sklearn
from imblearn.over_sampling import RandomOverSampler

ros = RandomOverSampler(sampling_strategy="minority")

X, y = ros.fit_resample(X, y)

#lets check if the label has been resampled
y.value_counts()

"""**Models**"""

#Importing necessary libraries for models
from sklearn.metrics import accuracy_score
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import cross_val_score
from collections import Counter
from IPython.core.display import display, HTML
sns.set_style('darkgrid')

# Splitting the dataset into the Training set and Test set
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 25)

"""Logistic Regression"""

# Importing the Logistic Regression Model
from sklearn.linear_model import LogisticRegression

# Fitting the Logistic Regression Model to the dataset
lr = LogisticRegression(multi_class='ovr', solver = 'liblinear')
lr_model = lr.fit(X_train, np.ravel(y_train))

#Evaluating the Logistic Regression Model
model_accuracy = lr_model.score(X_test, y_test)
print(" Model Accuracy:", model_accuracy)

"""Decision Tree Model"""

# Importing the Decision Tree Model
from sklearn.tree import DecisionTreeClassifier

# Fitting the Decision Tree Model to the dataset
dt_model = DecisionTreeClassifier(criterion='gini', random_state = 42, max_depth = 3, min_samples_leaf = 5)
dt = dt_model.fit(X_train, y_train)
dt

#plot of decision tree with each child node
target = list(pcos_new['PCOS (Y/N)'].unique())
feature_names = list(X.columns)

from sklearn.tree import export_text
r = export_text(dt_model, feature_names=feature_names)
print(r)

#Evaluating the Decision Tree model
y_pred = dt_model.predict(X_test)
model_accuracy = accuracy_score(y_test, y_pred)
print(" Model Accuracy:", model_accuracy)

"""Random Forest

"""

#Importing the Random Forest model
from sklearn.ensemble import RandomForestClassifier

#Fitting the Random Forest model to the dataset
rf = RandomForestClassifier(random_state= 40, n_estimators = 100)
rfc = rf.fit(X_train, y_train)
rfc

#Evaluating the Random Forest model
from sklearn.metrics import accuracy_score
y_pred = rf.predict(X_test)
model_accuracy = accuracy_score(y_test, y_pred)
print(" Model Accuracy:", model_accuracy)

#Visualizing the first three decision trees from the forest to help understand how the model is making predictions
from sklearn.tree import export_graphviz
from IPython.display import Image
import graphviz

for i in range(3):
    tree = rf.estimators_[i]
    dot_data = export_graphviz(tree,
                               feature_names=X_train.columns,
                               filled=True,
                               max_depth=2,
                               impurity=False,
                               proportion=True)
    graph = graphviz.Source(dot_data)
    display(graph)

#Hyperparameters tuning for the Random Forest model
from sklearn.model_selection import RandomizedSearchCV, train_test_split
from scipy.stats import randint

param_dist = {'n_estimators': randint(50,500),
              'max_depth': randint(1,20)}

# Creating a random forest classifier
rf = RandomForestClassifier()

# Using random search to find the best hyperparameters
rand_search = RandomizedSearchCV(rf,
                                 param_distributions = param_dist,
                                 n_iter=5,
                                 cv=5)

# Fitting the random search object to the data
rand_search.fit(X_train, y_train)
# Creating a variable for the best model
best_rf = rand_search.best_estimator_

# Printing the best hyperparameters
print('Best hyperparameters:',  rand_search.best_params_)

"""Support Vector Machines

"""

from sklearn import svm
from sklearn.model_selection import GridSearchCV

svm_model = svm.SVC()

para_grid = {'C' : [1, 10, 100, 1000], 'gamma': [1, 0.1, 0.01, 0.001], 'kernel':['rbf']}
grid = GridSearchCV(svm_model, para_grid, refit = True, verbose = 1, cv=5, n_jobs=-1)
svm = grid.fit(X_train, y_train)
svm

print(svm.best_params_)

model_accuracy = svm.best_score_
print(" Model Accuracy:", model_accuracy)

"""Gradient Boosting"""

from sklearn.ensemble import GradientBoostingClassifier

gbc = GradientBoostingClassifier(n_estimators=100).fit(X_train, y_train)

model_accuracy = gbc.score(X_test, y_test)
print(" Model Accuracy:", model_accuracy)

"""# **Confusion matrix and Classification report for Logistic regression**"""

from sklearn.metrics import confusion_matrix, classification_report
y_pred = lr_model.predict(X_test)
# Generate Confusion Matrix
conf_matrix = confusion_matrix(y_test, y_pred)
print("Confusion Matrix:")
print(conf_matrix)

class_report = classification_report(y_test, y_pred)
print("\nClassification Report:")
print(class_report)

"""# **Confusion matrix and Classification report for Decision Tree model**"""

from sklearn.metrics import confusion_matrix, classification_report
y_pred = dt.predict(X_test)
# Generate Confusion Matrix
conf_matrix = confusion_matrix(y_test, y_pred)
print("Confusion Matrix:")
print(conf_matrix)

class_report = classification_report(y_test, y_pred)
print("\nClassification Report:")
print(class_report)

"""# **Confusion matrix and Classification report for Random Forest**"""

y_pred = rfc.predict(X_test)
# Generate Confusion Matrix
conf_matrix = confusion_matrix(y_test, y_pred)
print("Confusion Matrix:")
print(conf_matrix)

class_report = classification_report(y_test, y_pred)
print("\nClassification Report:")
print(class_report)

"""# **Confusion matrix and Classification report for Support Vector machines**"""

y_pred = svm.predict(X_test)
# Generate Confusion Matrix
conf_matrix = confusion_matrix(y_test, y_pred)
print("Confusion Matrix:")
print(conf_matrix)

class_report = classification_report(y_test, y_pred)
print("\nClassification Report:")
print(class_report)

"""# **Confusion matrix and Classification report for Gradient Boosting**"""

y_pred = gbc.predict(X_test)
# Generate Confusion Matrix
conf_matrix = confusion_matrix(y_test, y_pred)
print("Confusion Matrix:")
print(conf_matrix)

class_report = classification_report(y_test, y_pred)
print("\nClassification Report:")
print(class_report)

"""**Justification of Model Selection**

Saving the trained model
"""

import pickle

filename = 'pcos_model.sav'
pickle.dump(svm, open(filename, 'wb'))

# loading the saved model
loaded_model = pickle.load(open('pcos_model.sav', 'rb'))

"""Making a predictive system"""

input_data = (3,3,0,0,0,2,1,0,2.07,44.6,19.3,5,0,28,30)

# changing the input_data to numpy array
input_data_as_numpy_array = np.asarray(input_data)

# reshape the array as we are predicting for one instance
input_data_reshaped = input_data_as_numpy_array.reshape(1,-1)

prediction = svm.predict(input_data_reshaped)
print(prediction)

if (prediction[0] == 0):
  print('The person does not have PCOS')
else:
  print('The person has PCOS')

for column in X.columns:
  print(column)